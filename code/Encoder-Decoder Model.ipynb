{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from PIL import Image,ImageOps\n",
    "from PIL import ImageDraw \n",
    "import shutil\n",
    "import os\n",
    "from PIL import Image\n",
    "import pickle\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator,array_to_img,img_to_array\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, LSTM, Input, Embedding, Conv2D, Concatenate, Flatten, Add, Dropout, GRU\n",
    "import random\n",
    "import datetime\n",
    "from nltk.translate.bleu_score import sentence_bleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_df_final.csv\",nrows=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>471</td>\n",
       "      <td>471</td>\n",
       "      <td>CXR1505_IM-0330</td>\n",
       "      <td>CXR1505_IM-0330-1001</td>\n",
       "      <td>CXR1505_IM-0330-2001</td>\n",
       "      <td>startseq normal heart size clear lungs no pneu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>CXR1007_IM-0008</td>\n",
       "      <td>CXR1007_IM-0008-1001</td>\n",
       "      <td>CXR1007_IM-0008-2001</td>\n",
       "      <td>startseq trachea is midline the cardiomediasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1499</td>\n",
       "      <td>1499</td>\n",
       "      <td>CXR2624_IM-1111</td>\n",
       "      <td>CXR2624_IM-1111-1001</td>\n",
       "      <td>CXR2624_IM-1111-2001</td>\n",
       "      <td>startseq heart size and mediastinal contour ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>54</td>\n",
       "      <td>54</td>\n",
       "      <td>CXR1054_IM-0040</td>\n",
       "      <td>CXR1054_IM-0040-1001</td>\n",
       "      <td>CXR1054_IM-0040-1002</td>\n",
       "      <td>startseq heart size is normal stable mediastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1411</td>\n",
       "      <td>1411</td>\n",
       "      <td>CXR2529_IM-1044</td>\n",
       "      <td>CXR2529_IM-1044-1001</td>\n",
       "      <td>CXR2529_IM-1044-2001</td>\n",
       "      <td>startseq the lungs are clear bilaterally speci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1       patient_id             image1_id  \\\n",
       "0         471           471  CXR1505_IM-0330  CXR1505_IM-0330-1001   \n",
       "1           9             9  CXR1007_IM-0008  CXR1007_IM-0008-1001   \n",
       "2        1499          1499  CXR2624_IM-1111  CXR2624_IM-1111-1001   \n",
       "3          54            54  CXR1054_IM-0040  CXR1054_IM-0040-1001   \n",
       "4        1411          1411  CXR2529_IM-1044  CXR2529_IM-1044-1001   \n",
       "\n",
       "              image2_id                                             report  \n",
       "0  CXR1505_IM-0330-2001  startseq normal heart size clear lungs no pneu...  \n",
       "1  CXR1007_IM-0008-2001  startseq trachea is midline the cardiomediasti...  \n",
       "2  CXR2624_IM-1111-2001  startseq heart size and mediastinal contour ar...  \n",
       "3  CXR1054_IM-0040-1002  startseq heart size is normal stable mediastin...  \n",
       "4  CXR2529_IM-1044-2001  startseq the lungs are clear bilaterally speci...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(\"test_df_final.csv\",nrows=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>CXR1009_IM-0010</td>\n",
       "      <td>CXR1009_IM-0010-1001</td>\n",
       "      <td>CXR1009_IM-0010-2001</td>\n",
       "      <td>startseq the cardiomediastinal silhouette and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>CXR1020_IM-0017</td>\n",
       "      <td>CXR1020_IM-0017-1001</td>\n",
       "      <td>CXR1020_IM-0017-2001</td>\n",
       "      <td>startseq lung volumes are low no focal infiltr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>24</td>\n",
       "      <td>CXR1022_IM-0017</td>\n",
       "      <td>CXR1022_IM-0017-1001</td>\n",
       "      <td>CXR1022_IM-0017-2001</td>\n",
       "      <td>startseq the heart and lungs have   in the int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25</td>\n",
       "      <td>25</td>\n",
       "      <td>CXR1023_IM-0018</td>\n",
       "      <td>CXR1023_IM-0018-1001</td>\n",
       "      <td>CXR1023_IM-0018-2001</td>\n",
       "      <td>startseq the cardiac silhouette and mediastinu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "      <td>CXR1026_IM-0021</td>\n",
       "      <td>CXR1026_IM-0021-2002</td>\n",
       "      <td>CXR1026_IM-0021-2002</td>\n",
       "      <td>startseq the lungs appear clear the heart and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  Unnamed: 0.1       patient_id             image1_id  \\\n",
       "0          11            11  CXR1009_IM-0010  CXR1009_IM-0010-1001   \n",
       "1          23            23  CXR1020_IM-0017  CXR1020_IM-0017-1001   \n",
       "2          24            24  CXR1022_IM-0017  CXR1022_IM-0017-1001   \n",
       "3          25            25  CXR1023_IM-0018  CXR1023_IM-0018-1001   \n",
       "4          28            28  CXR1026_IM-0021  CXR1026_IM-0021-2002   \n",
       "\n",
       "              image2_id                                             report  \n",
       "0  CXR1009_IM-0010-2001  startseq the cardiomediastinal silhouette and ...  \n",
       "1  CXR1020_IM-0017-2001  startseq lung volumes are low no focal infiltr...  \n",
       "2  CXR1022_IM-0017-2001  startseq the heart and lungs have   in the int...  \n",
       "3  CXR1023_IM-0018-2001  startseq the cardiac silhouette and mediastinu...  \n",
       "4  CXR1026_IM-0021-2002  startseq the lungs appear clear the heart and ...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0.1',axis='columns',inplace=True)\n",
    "test.drop('Unnamed: 0.1',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop('Unnamed: 0',axis='columns',inplace=True)\n",
    "test.drop('Unnamed: 0',axis='columns',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1505_IM-0330</td>\n",
       "      <td>CXR1505_IM-0330-1001</td>\n",
       "      <td>CXR1505_IM-0330-2001</td>\n",
       "      <td>startseq normal heart size clear lungs no pneu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1007_IM-0008</td>\n",
       "      <td>CXR1007_IM-0008-1001</td>\n",
       "      <td>CXR1007_IM-0008-2001</td>\n",
       "      <td>startseq trachea is midline the cardiomediasti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR2624_IM-1111</td>\n",
       "      <td>CXR2624_IM-1111-1001</td>\n",
       "      <td>CXR2624_IM-1111-2001</td>\n",
       "      <td>startseq heart size and mediastinal contour ar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1054_IM-0040</td>\n",
       "      <td>CXR1054_IM-0040-1001</td>\n",
       "      <td>CXR1054_IM-0040-1002</td>\n",
       "      <td>startseq heart size is normal stable mediastin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR2529_IM-1044</td>\n",
       "      <td>CXR2529_IM-1044-1001</td>\n",
       "      <td>CXR2529_IM-1044-2001</td>\n",
       "      <td>startseq the lungs are clear bilaterally speci...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id             image1_id             image2_id  \\\n",
       "0  CXR1505_IM-0330  CXR1505_IM-0330-1001  CXR1505_IM-0330-2001   \n",
       "1  CXR1007_IM-0008  CXR1007_IM-0008-1001  CXR1007_IM-0008-2001   \n",
       "2  CXR2624_IM-1111  CXR2624_IM-1111-1001  CXR2624_IM-1111-2001   \n",
       "3  CXR1054_IM-0040  CXR1054_IM-0040-1001  CXR1054_IM-0040-1002   \n",
       "4  CXR2529_IM-1044  CXR2529_IM-1044-1001  CXR2529_IM-1044-2001   \n",
       "\n",
       "                                              report  \n",
       "0  startseq normal heart size clear lungs no pneu...  \n",
       "1  startseq trachea is midline the cardiomediasti...  \n",
       "2  startseq heart size and mediastinal contour ar...  \n",
       "3  startseq heart size is normal stable mediastin...  \n",
       "4  startseq the lungs are clear bilaterally speci...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>image1_id</th>\n",
       "      <th>image2_id</th>\n",
       "      <th>report</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CXR1009_IM-0010</td>\n",
       "      <td>CXR1009_IM-0010-1001</td>\n",
       "      <td>CXR1009_IM-0010-2001</td>\n",
       "      <td>startseq the cardiomediastinal silhouette and ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CXR1020_IM-0017</td>\n",
       "      <td>CXR1020_IM-0017-1001</td>\n",
       "      <td>CXR1020_IM-0017-2001</td>\n",
       "      <td>startseq lung volumes are low no focal infiltr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CXR1022_IM-0017</td>\n",
       "      <td>CXR1022_IM-0017-1001</td>\n",
       "      <td>CXR1022_IM-0017-2001</td>\n",
       "      <td>startseq the heart and lungs have   in the int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>CXR1023_IM-0018</td>\n",
       "      <td>CXR1023_IM-0018-1001</td>\n",
       "      <td>CXR1023_IM-0018-2001</td>\n",
       "      <td>startseq the cardiac silhouette and mediastinu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CXR1026_IM-0021</td>\n",
       "      <td>CXR1026_IM-0021-2002</td>\n",
       "      <td>CXR1026_IM-0021-2002</td>\n",
       "      <td>startseq the lungs appear clear the heart and ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id             image1_id             image2_id  \\\n",
       "0  CXR1009_IM-0010  CXR1009_IM-0010-1001  CXR1009_IM-0010-2001   \n",
       "1  CXR1020_IM-0017  CXR1020_IM-0017-1001  CXR1020_IM-0017-2001   \n",
       "2  CXR1022_IM-0017  CXR1022_IM-0017-1001  CXR1022_IM-0017-2001   \n",
       "3  CXR1023_IM-0018  CXR1023_IM-0018-1001  CXR1023_IM-0018-2001   \n",
       "4  CXR1026_IM-0021  CXR1026_IM-0021-2002  CXR1026_IM-0021-2002   \n",
       "\n",
       "                                              report  \n",
       "0  startseq the cardiomediastinal silhouette and ...  \n",
       "1  startseq lung volumes are low no focal infiltr...  \n",
       "2  startseq the heart and lungs have   in the int...  \n",
       "3  startseq the cardiac silhouette and mediastinu...  \n",
       "4  startseq the lungs appear clear the heart and ...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 4), (200, 4))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test = train['patient_id'], test['patient_id']\n",
    "y_train, y_test = train['report'], test['report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000,), (1000,), (200,), (200,))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters='!\"#$%&()*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n')\n",
    "tokenizer.fit_on_texts(y_train.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('train_features_list.pkl', 'rb') as f:\n",
    "    train_feat_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('test_features_list.pkl', 'rb') as f:\n",
    "    test_feat_list = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_feat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('C:/Users/INDIRA/Downloads/data rescon/glove.840B.300d.pkl','rb') # 300d glove vectors  \n",
    "glove_vectors = pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(tokenizer.word_index.keys()) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((vocab_size,300))\n",
    "for word, i in tokenizer.word_index.items():\n",
    "    if word in glove_vectors.keys():\n",
    "        vec = glove_vectors[word]\n",
    "        embedding_matrix[i] = vec\n",
    "    else:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_feat_list,y_train))\n",
    "train_dataset = train_dataset.shuffle(300).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((test_feat_list,y_test))\n",
    "test_dataset = test_dataset.shuffle(300).batch(batch_size).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(images,reports_unpadded):\n",
    "    imgs = []\n",
    "    input_reports = []\n",
    "    output_reports = []\n",
    "    for i in range(len(images)):\n",
    "        sequence=[] \n",
    "        for rep in reports_unpadded[i].split(\" \"):\n",
    "            if rep in tokenizer.word_index.keys():\n",
    "                sequence.append(tokenizer.word_index[rep])\n",
    "        for j in range(1,len(sequence)):\n",
    "            in_seq = sequence[:j]          \n",
    "            out_seq = sequence[j]            \n",
    "            out_seq = tf.keras.utils.to_categorical(out_seq, num_classes=vocab_size)\n",
    "            imgs.append(images[i])            \n",
    "            input_reports.append(in_seq)            \n",
    "            output_reports.append(out_seq)\n",
    "        \n",
    "    return np.array(imgs), np.array(input_reports), np.array(output_reports)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = tf.keras.losses.CategoricalCrossentropy(from_logits=False, reduction='auto')\n",
    "def maskedLoss(y_true, y_pred):\n",
    "    mask = tf.math.logical_not(tf.math.equal(y_true, 0))\n",
    "    loss_ = loss_function(y_true, y_pred)\n",
    "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
    "    loss_ = loss_*mask\n",
    "    loss_ = tf.reduce_mean(loss_)\n",
    "    return loss_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=80"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "text (InputLayer)               [(None, 80)]         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 80, 300)      330600      text[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "LSTM1 (LSTM)                    (None, 80, 256)      570368      embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "Images (InputLayer)             [(None, 2048)]       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "LSTM2 (LSTM)                    (None, 512)          1574912     LSTM1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "enc_dense (Dense)               (None, 512)          1049088     Images[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 512)          0           LSTM2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 512)          0           enc_dense[0][0]                  \n",
      "                                                                 dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 512)          262656      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 512)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1102)         565326      dropout_1[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 4,352,950\n",
      "Trainable params: 4,022,350\n",
      "Non-trainable params: 330,600\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "input_1=Input(shape=(2048),name=\"Images\")\n",
    "encoder_out=Dense(512,activation=\"relu\",name=\"enc_dense\")(input_1)\n",
    "\n",
    "\n",
    "#decoder model\n",
    "input_text=Input(shape=(max_len),name=\"text\")\n",
    "\n",
    "embedding_out=tf.keras.layers.Embedding(input_dim=vocab_size,output_dim=300,input_length=max_len,mask_zero=True,trainable=False,weights=[embedding_matrix])(input_text)\n",
    "\n",
    "lstm_out= LSTM(units=256, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), return_sequences=True, name=\"LSTM1\")(embedding_out)\n",
    "\n",
    "lstm_out= LSTM(units=512, activation='tanh', recurrent_activation='sigmoid', use_bias=True, \n",
    "            kernel_initializer=tf.keras.initializers.glorot_uniform(seed=23),\n",
    "            recurrent_initializer=tf.keras.initializers.orthogonal(seed=7),\n",
    "            bias_initializer=tf.keras.initializers.zeros(), name=\"LSTM2\")(lstm_out) \n",
    "\n",
    "x=Dropout(0.35)(lstm_out)\n",
    "add=tf.keras.layers.Add()([encoder_out, x])\n",
    "  \n",
    "x=Dense(512,kernel_initializer=tf.keras.initializers.he_normal(seed=1),activation=\"relu\")(add)\n",
    "\n",
    "x1=Dropout(0.25)(x)\n",
    "\n",
    "x1=Dense(vocab_size,activation=\"softmax\")(x1)\n",
    "#encoder_decoder_model\n",
    "encoder_decoder=Model(inputs=[input_1,input_text],outputs=x1)\n",
    "encoder_decoder.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_decoder.compile(optimizer=\"Adam\", loss = maskedLoss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH :  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-24-9aa7dabe9026>:18: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
      "  return np.array(imgs), np.array(input_reports), np.array(output_reports)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Loss: 0.004779368519049251\n",
      "EPOCH :  2\n",
      "Training Loss: 0.004259754614340085\n",
      "EPOCH :  3\n",
      "Training Loss: 0.0038818792320054136\n",
      "EPOCH :  4\n",
      "Training Loss: 0.0034573689018460836\n",
      "EPOCH :  5\n",
      "Training Loss: 0.003014479336949686\n",
      "EPOCH :  6\n",
      "Training Loss: 0.0026333709176855555\n",
      "EPOCH :  7\n",
      "Training Loss: 0.002369077343521922\n",
      "EPOCH :  8\n",
      "Training Loss: 0.002172225320739954\n",
      "EPOCH :  9\n",
      "Training Loss: 0.002011224671591525\n",
      "EPOCH :  10\n",
      "Training Loss: 0.0018691809876172831\n"
     ]
    }
   ],
   "source": [
    "train_loss_list = []\n",
    "\n",
    "for epoch in range(10):\n",
    "    print('EPOCH : ',epoch+1)\n",
    "    batch_loss_train = 0\n",
    "    \n",
    "    for img, report in train_dataset:        \n",
    "        r1 = [word.decode('utf-8') for word in np.array(report)]  \n",
    "        img_input, rep_input, output_word = load_data(img.numpy(), r1)\n",
    "        rep_input = tf.keras.preprocessing.sequence.pad_sequences(rep_input, maxlen=80, padding='post')\n",
    "        img_input=tf.reshape(img_input,shape=(img_input.shape[0],img_input.shape[-1]))        \n",
    "        loss = encoder_decoder.train_on_batch([img_input, rep_input], output_word)        \n",
    "        batch_loss_train += loss\n",
    "\n",
    "    train_loss = batch_loss_train/(len(y_train)//15)\n",
    "    print('Training Loss: {}'.format(train_loss))\n",
    "    \n",
    "encoder_decoder.save_weights('encoder_decoder_epoch_'+ str(epoch+1) + '.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_preprocess(img):\n",
    "    img=img_to_array(img)\n",
    "    img=preprocess_input(img)\n",
    "    img=cv2.resize(img,(224,224))\n",
    "    img=img/255.0\n",
    "    img=np.expand_dims(img, axis=0)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import DenseNet121\n",
    "\n",
    "image_shape= (224,224,3)\n",
    "mod2=DenseNet121(include_top=False,input_shape=image_shape,pooling=\"avg\")\n",
    "las2=Dense(14,\"sigmoid\")(mod2.output)\n",
    "\n",
    "mod2=Model(inputs=mod2.input,outputs=las2)\n",
    "mod2.load_weights(\"c:/Users/INDIRA/Downloads/data rescon/chexnet_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_chexnet_model=Model(inputs=mod2.inputs,outputs=mod2.layers[-2].output,name=\"Chexnet_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_1= tf.keras.Input(shape=(224,224,3),name=\"image_1_features\")\n",
    "image_2= tf.keras.Input(shape=(224,224,3),name=\"image_2_features\")\n",
    "image_1_out=final_chexnet_model(image_1)\n",
    "image_2_out=final_chexnet_model(image_2)\n",
    "conc=tf.keras.layers.Concatenate(axis=-1)([image_1_out,image_2_out])\n",
    "feature_extraction_model=Model(inputs=[image_1,image_2],outputs=conc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(image1,image2):\n",
    "    image_features=feature_extraction_model([image1,image2])\n",
    "    output_report=''\n",
    "    input_rep= 'startseq'\n",
    "    image_features=tf.reshape(image_features,shape=(-1,image_features.shape[-1]))\n",
    "    for i in range(max_len):\n",
    "        input_tokens = [tokenizer.word_index[w] for w in input_rep.split()]\n",
    "        input_padded = tf.keras.preprocessing.sequence.pad_sequences([input_tokens],max_len, padding='post')\n",
    "        results = encoder_decoder.predict([image_features,input_padded])\n",
    "        arg = np.argmax(results[0]) \n",
    "        if tokenizer.index_word[arg]=='endseq':\n",
    "            output_report+=tokenizer.index_word[arg]+\" \"\n",
    "            break\n",
    "        else:\n",
    "            input_rep = input_rep + ' ' + tokenizer.index_word[arg]\n",
    "            output_report = output_report+tokenizer.index_word[arg]+\" \"\n",
    "    return output_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Report:  startseq the cardiomediastinal silhouette and pulmonary vasculature are within normal limits there is no pneumothorax or pleural effusion there are no focal areas of consolidation endseq\n",
      "Generated Report:  the heart is normal in size the mediastinum is unremarkable the lungs are clear endseq \n",
      "BLEU SCORE IS:  1.1930496181487654e-231\n"
     ]
    }
   ],
   "source": [
    "img1=Image.open('C:/Users/INDIRA/Downloads/data rescon/images/CXR1009_IM-0010-1001'+'.png')\n",
    "img2=Image.open('C:/Users/INDIRA/Downloads/data rescon/images/CXR1009_IM-0010-2001'+'.png')\n",
    "img1=img_preprocess(img1)\n",
    "img2=img_preprocess(img2)\n",
    "result=evaluation(img1,img2) \n",
    "actual=y_test[0]\n",
    "print(\"Actual Report: \",actual)\n",
    "print(\"Generated Report: \",result) \n",
    "print(\"BLEU SCORE IS: \",sentence_bleu(actual,result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual Report:  startseq the lungs appear clear the heart and pulmonary  appear normal the pleural spaces are clear mediastinal contours are normal endseq\n",
      "Generated Report:  the heart is normal in size the mediastinum is unremarkable there is no pleural effusion or pneumothorax there is no focal air space opacity to suggest a pneumonia there is a calcified granuloma in the right lung base there are no acute bony findings endseq \n",
      "BLEU SCORE IS:  9.490559085273313e-232\n"
     ]
    }
   ],
   "source": [
    "img1=Image.open('C:/Users/INDIRA/Downloads/data rescon/images/CXR1026_IM-0021-2002'+'.png')\n",
    "img2=Image.open('C:/Users/INDIRA/Downloads/data rescon/images/CXR1026_IM-0021-2002'+'.png')\n",
    "img1=img_preprocess(img1)\n",
    "img2=img_preprocess(img2)\n",
    "result=evaluation(img1,img2) \n",
    "actual=y_test[4]\n",
    "print(\"Actual Report: \",actual)\n",
    "print(\"Generated Report: \",result) \n",
    "print(\"BLEU SCORE IS: \",sentence_bleu(actual,result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
